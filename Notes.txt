Conditional Probability:
P(a|b) = P(a ^ b) / P(b)
P(a ^ b) = P(a|b)P(b)
P(a ^ b) = P(b|a)P(a)

P(a|b)P(b) = P(b|a)P(a)
P(a|b) = P(b|a)P(a) / P(b) <= Bayes' Rule
P(b|a) = P(a|b)P(b) / P(a) <= Bayes' Rule

Bayes' Rule: 
Knowing - P(visible effect|unknown cause)
We can conclude - P(unknown cause | visible effect)

Example:
Knowing - P(medical test result | disease)
We can conclude - P(disease | medical test result)

If Probability of 'a' and 'b' are independent,
P(a ^ b) = P(b)P(a)

P(a∣b) = P(b∣a)P(A) / P(B)

Bayes rule/formula:
Prior Odds: 5:95
Likelihood Ratio: P(A|B) / P(A|C) : (80/100) / (10/100) = (80/100) * (100/10) = 80/10 = 8
Posterior Odds: 40:95

Joint Probability:
P(A|b) = P(A, b) / P(b) : Comma signifies ^
       = alpha * P(A, b), where alpha = 1/P(b) which is just some constant.
       = alpha * <Probability distribution of 'b' which sums up to 1>
=> Conditional probability is proportional to Joint probability

Inclusion-Exclusion:
P(a v b) = P(a) + P(b) - P(a^b)

Marginalization: Calculate probability of independent variable based on given/known joint probabilities.
P(a) = P(a,b) + P(a, Not(b))
P(X = xi) = Summation over all the values (j) y could take on of P(X = xi, Y = yj)

Conditioning: Calculate probability of independent variable based on given/known conditional probabilities.
P(a) = P(a|b)P(b) + P(a|Not(b))P(Not(b))
P(X = xi) = Summation over all the values (j) y could take on of P(X = xi|Y = yj)P(Y = yj)

Bayesian Network: Data structure which represents the dependencis among random variables.
- Directed graph
- Each node represents a random variable.
- Arrow from X to Y means X is a parent of Y
- Each node X has a probability distrubution P(X | Parents(X))

Inference:
- Query X: variable for which to compute distribution
- Evidence variables E: observed variables for event e
- Hidden variables Y: non-evidence and non-query variable
- Goal: Calculate P(X | e) where e could be more than 1.

Inference by Enumeration:
P(X | e) = alpha * P(X,e) = alpha * Summation over all the values (j) y could take on of P(X, e, y)
X: query variable
e: evidence
y: ranges over values of hidden variables
alpha: normalizes the result.
Cons: Time complexity grows with complexity of the network

Aproximate Inference:
- Sampling:
  - Rejection Sampling: Filter out samples which do not match event specification
  - Likelihood Weighting:
    - Start by fixing the values of evidence variables.
    - Sample the non-evidence variables using conditional probabilities in the Bayesian Network
    - Weight each sample by its likelihood: the probability of all of the evidence.

Markov Assumption: The assumption that the current state depends on only a finite fixed number of previous states.
Markov Chain: A sequence of random variables where the distribution of each variable follows the Markov assumption.
Hidden Markov Model: a Markov model for a system with hidden states which generate some observed events.
Sensor Markov Assumption: the assumption that the evidence variable depends only on corresponding state.

Supervised Learning > Classification:
Perceptron Learning Rule: Given data point (x,y), update each weight according to: w =  w + alpha*(y - h(X)) * x
Start with random weights, learn from data and update the weights that result in better weight vector which reduces loss.

Support Vector Machines:
  Maximum Margin Separator: Boundary that maximizes the distance between any of the data points
If the data is not linearly separable, it works from higher dimension to find the separation boundary. For example, other shapes than linear lines.

Optimization Problem Formulation:
- Local Search: 
  - Algorithms: Hill-Climbing, Simulated Annealing
- Linear Programming
  - Algorithms: 
- Constraint Satisfaction
  - Algorithms: AC3, Backtracking

Supervised Learning > Regression:
Learning a function mapping an input point to a continuous value.

Types of loss functions:
0-1 Loss: Used in discrete classification
L1 Loss: |actual - prediction| -> Used in continuous number prediction. Used when we don't care about outliers.
L2 Loss: (actual - prediction)^2 -> Penalizes worse / bigger loss more harshly. Used when we care about outliers.

Overfitting:
A model that fits too closely to a particular data set and therefore may fail to generalize to future data.
This is a side effect of minimizing loss of a model. If loss = 0, the model may only work on the specific data set.
One way to counter this problem is add other parameters to optimization. For example, consider complexity:

Cost(h) = Loss(h) + w*Complexity(h) : 'w' gives weight to the complexity

Adding the term w*Complexity(h) is called "Regularization": Penalizing hypotheses that are more complex to favour simpler, more general hypotheses

Hold-out cross validation splits data into training and testing data sets. How to split?
k-fold corss-validation: Splitting data into k sets, and experimenting k times, using each set as a test set once, and using remaining data as training set.

Reinforcement Learning:
Given a set of rewards or penalties, learn what actions to take in the future.
Markov Decision Process:
Model for decision-making, representing states, actions, and their rewards.
Q-Learning:
Method for learning a function Q(s,a), estimate of the value (reward) of performing action 'a' in state 's'. Start with Q(s,a) = 0 for all s,a.
Q(s,a) <- Q(s,a) + w*(new estimate - old estimate): w:0 old values are more important; w:1 new values are more important.
Q(s,a) <- Q(s,a) + w*((r + future reward estimate) - Q(s,a)) 
Q(s,a) <- Q(s,a) + w*((r + w1*max(Q(s',a') for all a')) - Q(s,a)): w1 provides weights for future vs current reward

Balance between Exploration and Exploitation.

Function Approximation:
Approximating Q(s,a), often by a function combining various features, rathen than storing one value for every state-action pair.
Similar to depth-limiting approach in MiniMax. Used when it is not feasible to explore all the posible values of Q(s,a) in a bigger state space.

Unsupervised Learning:
Given input data without any additional feedback (label), learn patterns, find structure in the data.
Tasks:
(1) Clustering: Organize a set of objects into groups in such a way that similar objects tend to be in the same group. Example: Genetic research, Image segmentation, Market research, Medical imaging, Social network analysis.
    One technique is k-means clustering: Algorithm for clustering data based on repeatedly assigning points to clusters (k number of clusters) and updating those clusters' centers
(2) Anomaly Detection: Find unusual events in the data.
    Use case: Fraud detection.
(3) Dimensionality Reduction: Compress large corpuses of data to a much smaller dataset without losing key / important information.
Neural Network:
Activation functions:
(1) Step function: g(x) = 1 if x >=0, else 0
(2) Logistic Sigmoid: g(x) = e^x / (1 + e^x)
(3) Rectifier Linear Unit (ReLu): g(x) = max(0,x)
h(x1,x2) = g(w0 + w1x1 + w2x2 + ...)
Example:
(1) To mdel the OR function:
    h(x1,x2) = g(-1 + x1 + x2); w0 = -1, w1=w2=1
(2) To mdel the AND function:
    h(x1,x2) = g(-2 + x1 + x2); w0 = -2, w1=w2=1
Training - to calculate the parameters:
- Trade-offs between speed and accuracy
(1) Gradient Descent: Algorithm for minimizing loss when training NN
    Start with a random choice of weights, repeat:
    - Calculate the gradient based on ALL data points (training data set): direction that will lead to decreasing loss
    - Update weights according to the gradient
(2) Stochastic Gradient Descent: Same as Gradient Descent but "... based on ONE data point"
(3) Mini-Batch Gradient Descent: Same as Gradient Descent but "... based on ONE SMALL BATCH of data points"
Perceptron: Only capable of learning linearly separable decision boundary
Multilayer NN: Artificial NN with an input layer, an output layer, and at least one hidden layer. Capable of modelling more complex problems compared to perceptron.
To train multi-layer NN, we have to propagate the loss/error from the output back to the hidden layers:
Backpropagation: Algorithm for training NN with hidden layers
    Start with a random choice of weights, repeat:
    - Calculate error for output layer
    - For each layer, starting with output layer, and moving inwards towards the earliest hidden layer
      - Propagate error back one layer
To prevent Overfitting:
Dropout: Temporarily removing units - selected at random - from a NN to prevent over-reliance on certain units
playground.tensorflow.org
Image Convolution: Applying a filter that adds each pixel value of an image to it's neighbours, weighted according to a kernel matrix.
                  - Extracts features from input. Output is a feature map
Pooling: reducing the size of an input by sampling from regions in the input
(1) Max-pooling: pooling by choosing the maximum vallue in each region
Convolutional NN: NN that uses convolution, usually for analyzing images (i.e., Image Convolution + Pooling in a NN)
                - Training is done to figure out what's the best filters for the input image
                - Models how human look at images
Input image -> [Convolution (calculates filters) -> Pooling (Summarize and reduces the size of inputs)] -> Flattening (Feeds into the inputs of NN)
[Convolution -> Pooling] can be applied multiple times before Flattening. Early layers of this to discover low-level features (Edges, Curves, Shapes); later layers to discover high-level features (objects, person, face, etc)

Feed-forward NN: Good for classification. 1:1 mapping from input to output -Single-valued output.
Recurrent NN: Output from the NN is fed to it's input for future calculation. It maintains some states. Good for dealing with sequences of data, both input and/or output. N:N mapping from input to output - Output sequence of values.
              Example applications: Youtube to analyze videos, Google translator, etc
              One example is Long Short Memory Network
=========================================================================================================================================================================================================================================
File formats for training and evaluation.
For large data sets, load the data from data warehouse into SSD storage (Cloud or local). This will prevent underusage of resources, GPU/CPU during the traning/evaluation process.
JSONL: JSON Lines is a simple text-based format with rows. It is human readable and an ideal choice for small to medium-sized datasets.
TFRecord: Binary format and easier to read for computers, ideal for efficient training.
Parquet: Good for large and complex datasets.